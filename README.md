# ğŸš€ ModelServeX

ModelServeX is a lightweight and scalable web application that enables seamless deployment of machine learning models as REST APIs.  
It simplifies the process of serving trained models, making them accessible to applications, researchers, and developers without worrying about infrastructure complexities.

---

## âœ¨ Features
- ğŸ“¦ Deploy machine learning models as REST APIs  
- âš¡ Fast and lightweight (built with **FastAPI**)  
- ğŸŒ Ready-to-use endpoints for model inference  
- ğŸ”’ Secure and reliable with structured error handling  
- â˜ï¸ Deployable on **Render**, **Docker Hub**, or any cloud service  

---

## ğŸ› ï¸ Tech Stack
- **Backend:** Python, FastAPI  
- **Model Serving:** TensorFlow (CIFAR-10 image classification model)  
- **Deployment:** Docker & Render  

---

## ğŸ“‚ Project Structure
ModelServeX/ â”‚â”€â”€ app.py # Main FastAPI application â”‚â”€â”€ model.h5 # Pre-trained CIFAR-10 model â”‚â”€â”€ train.py # Training script â”‚â”€â”€ try.py # Local testing script â”‚â”€â”€ requirements.txt # Python dependencies â”‚â”€â”€ Dockerfile # Docker setup â”‚â”€â”€ .gitignore # Files ignored in version control â”‚â”€â”€ README.md # Project documentation

Code

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/aakarsh5/ModelServeX.git
cd ModelServeX
```
2. Create a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows
```
4. Install Dependencies
```bash
pip install -r requirements.txt
```
6. Run the Application
```bash
uvicorn app:app --host 0.0.0.0 --port 8000
The server will start at: ğŸ‘‰ http://127.0.0.1:8000 Swagger UI available at: ğŸ‘‰ http://127.0.0.1:8000/docs
```

ğŸ“¡ API Endpoints
Root Endpoint
http
GET /
Response:

json
{ "message": "Welcome to ModelServeX API" }
Prediction Endpoint
http
POST /predict
Request Body (JSON):

json
{ "input": [ /* image array data */ ] }
Response:

json
{ "prediction": "airplane" }
ğŸ§ª Predict via Swagger UI (/docs)
ModelServeX includes an interactive frontend powered by FastAPI's Swagger UI, accessible at:

ğŸ‘‰ http://127.0.0.1:8000/docs

This allows users to test the /predict endpoint directly from their browser.

ğŸ–¼ï¸ How to Use
Download a CIFAR-10 image You can grab sample images from the CIFAR-10 dataset or use any 32Ã—32 RGB image.

Open Swagger UI Navigate to http://127.0.0.1:8000/docs

Click on /predict â†’ Try it out â†’ Choose File Upload your image (e.g., cat.png, truck.jpg, etc.)

Execute The API will return a JSON response with:

predicted_class: e.g., "dog"

confidence: e.g., 0.968

probabilities: dictionary of class-wise scores

â˜ï¸ Deployment on Render
Push your code to GitHub

Go to Render and create a new Web Service

Connect your GitHub repository

Set the following:

Build Command: pip install -r requirements.txt

Start Command: uvicorn app:app --host 0.0.0.0 --port 8000

Your model API will be live! ğŸ‰

ğŸ¤ Contributing
Contributions are welcome! Please fork the repo and submit a pull request.

ğŸ“œ License
This project is licensed under the MIT License.

ğŸ‘¨â€ğŸ’» Author
Developed by Aakarsh Lohani GitHub: @aakarsh5
